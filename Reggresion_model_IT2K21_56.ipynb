{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sanidhyar10/Intro-to-Data-Science-using-python-/blob/main/Reggresion_model_IT2K21_56.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9: Regression Modelling"
      ],
      "metadata": {
        "id": "QqrMQe1CUDTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression modeling, in simple terms, is a statistical approach used to understand and quantify the relationship between one variable (the \"dependent\" or \"outcome\" variable) and one or more other variables (the \"independent\" or \"predictor\" variables). The primary goal is to develop a mathematical equation that can predict or explain the values of the dependent variable based on the values of the independent variables.\n",
        "\n",
        "Here's a breakdown:\n",
        "\n",
        "Dependent Variable: This is what you're trying to predict or understand. For example, it could be sales, temperature, exam scores, etc.\n",
        "\n",
        "Independent Variables: These are the factors that you believe may influence or explain changes in the dependent variable. They could be things like time, price, age, etc.\n",
        "\n",
        "Regression Equation: The model aims to find an equation that best fits the data. This equation helps us understand how changes in the independent variables relate to changes in the dependent variable.\n",
        "\n",
        "Parameter Estimation: During modeling, the algorithm estimates parameters (coefficients) for each independent variable. These coefficients tell us the strength and direction of the relationship.\n",
        "\n",
        "Prediction: Once the model is trained, it can be used to make predictions. For example, if we know the values of the independent variables, we can use the model to predict the value of the dependent variable.\n",
        "\n",
        "In essence, regression modeling is a tool that helps us explore and quantify relationships between variables, making it valuable in fields such as economics, finance, biology, and many others. It's a fundamental part of data analysis and predictive modeling."
      ],
      "metadata": {
        "id": "-v3YLPvVT-Pd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Z-L5VINPqS2",
        "outputId": "26b45e60-7bd5-4232-88bc-e1a8b76093c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Sales per Visit for the first customer: 0.4413253722522675\n",
            "Mean Absolute Error (MAE): 0.3917367069586419\n",
            "R-squared (R^2): 0.24242210357043603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "# Load the dataset (replace 'bank.csv' with the actual path to your dataset)\n",
        "bank_data = pd.read_csv('/content/bank.csv')\n",
        "\n",
        "# Replace these columns with your actual predictor and response variable names\n",
        "predictor_columns = [\"age\", \"balance\", \"day\", \"duration\", \"campaign\", \"pdays\", \"previous\"]\n",
        "\n",
        "response_column = \"deposit\"\n",
        "\n",
        "# Assuming categorical variables are already one-hot encoded\n",
        "# If not, use bank_data = pd.get_dummies(bank_data, columns=[\"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\", \"contact\", \"month\", \"poutcome\"])\n",
        "\n",
        "# Convert 'yes' and 'no' to 1 and 0\n",
        "bank_data[response_column] = bank_data[response_column].map({'yes': 1, 'no': 0})\n",
        "\n",
        "# Split the data into training and test sets\n",
        "bank_train, bank_test = train_test_split(bank_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create predictor and response variables for the training set\n",
        "X_train = bank_train[predictor_columns]\n",
        "y_train = bank_train[response_column]\n",
        "\n",
        "# Create predictor and response variables for the test set\n",
        "X_test = bank_test[predictor_columns]\n",
        "y_test = bank_test[response_column]\n",
        "\n",
        "# Fit a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "# Replace these values with actual values for the customer you want to predict\n",
        "duration_value = 1000\n",
        "campaign_value = 2\n",
        "pdays_value = -1\n",
        "previous_value = 0\n",
        "\n",
        "# Predict sales per visit for the first customer\n",
        "cust01 = np.array([[1, 0, 333, duration_value, campaign_value, pdays_value, previous_value]])\n",
        "predicted_sales = model.predict(cust01)\n",
        "print(\"Predicted Sales per Visit for the first customer:\", predicted_sales[0])\n",
        "\n",
        "# Predict sales per visit for all customers in the test set\n",
        "ypred = model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = metrics.mean_absolute_error(y_test, ypred)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "\n",
        "# Calculate R-squared\n",
        "rsquared = model.score(X_test, y_test)\n",
        "print(\"R-squared (R^2):\", rsquared)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.2 Demonstrate Stepwise Regression Using R/Python"
      ],
      "metadata": {
        "id": "1bbIchUTUNz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the dataset (replace 'bank.csv' with the actual path to your dataset)\n",
        "bank_data = pd.read_csv('/content/bank.csv')\n",
        "\n",
        "# Replace these columns with your actual predictor and response variable names\n",
        "predictor_columns = [\"age\", \"balance\", \"day\", \"duration\", \"campaign\", \"pdays\", \"previous\"]\n",
        "response_column = \"deposit\"\n",
        "\n",
        "# Assuming categorical variables are already one-hot encoded\n",
        "# If not, use bank_data = pd.get_dummies(bank_data, columns=[\"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\", \"contact\", \"month\", \"poutcome\"])\n",
        "\n",
        "# Convert 'yes' and 'no' to 1 and 0\n",
        "bank_data[response_column] = bank_data[response_column].map({'yes': 1, 'no': 0})\n",
        "\n",
        "# Create predictor and response variables\n",
        "X = bank_data[predictor_columns]\n",
        "y = bank_data[response_column]\n",
        "\n",
        "# Implement forward stepwise selection\n",
        "def forward_select(X, y):\n",
        "    selected_vars = set()\n",
        "    remaining_vars = set(X.columns)\n",
        "    best_model = None\n",
        "    best_aic = np.inf\n",
        "\n",
        "    for _ in tqdm(range(len(X.columns))):\n",
        "        models = {}\n",
        "        for var in remaining_vars:\n",
        "            predictors = list(selected_vars) + [var]\n",
        "            X_subset = X[predictors]\n",
        "            X_subset = sm.add_constant(X_subset)\n",
        "            model = sm.OLS(y, X_subset).fit()\n",
        "            models[var] = model.aic\n",
        "\n",
        "            if model.aic < best_aic:\n",
        "                best_aic = model.aic\n",
        "                best_model = model\n",
        "                best_var = var\n",
        "\n",
        "        selected_vars.add(best_var)\n",
        "        remaining_vars.remove(best_var)\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# Run forward stepwise selection\n",
        "final_model = forward_select(X, y)\n",
        "\n",
        "# Display the summary of the final model\n",
        "print(final_model.summary())"
      ],
      "metadata": {
        "id": "utLGtetgUXRp",
        "outputId": "68eb62b8-da60-44b9-aec7-bcc77669585c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:00<00:00, 11.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                deposit   R-squared:                       0.252\n",
            "Model:                            OLS   Adj. R-squared:                  0.251\n",
            "Method:                 Least Squares   F-statistic:                     535.5\n",
            "Date:                Fri, 08 Dec 2023   Prob (F-statistic):               0.00\n",
            "Time:                        08:48:32   Log-Likelihood:                -6469.1\n",
            "No. Observations:               11162   AIC:                         1.295e+04\n",
            "Df Residuals:                   11154   BIC:                         1.301e+04\n",
            "Df Model:                           7                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.1950      0.018     11.012      0.000       0.160       0.230\n",
            "campaign      -0.0165      0.002    -10.802      0.000      -0.019      -0.013\n",
            "balance     9.682e-06   1.28e-06      7.580      0.000    7.18e-06    1.22e-05\n",
            "previous       0.0196      0.002      9.436      0.000       0.015       0.024\n",
            "pdays          0.0005   4.39e-05     11.122      0.000       0.000       0.001\n",
            "age            0.0011      0.000      3.056      0.002       0.000       0.002\n",
            "duration       0.0006   1.18e-05     55.034      0.000       0.001       0.001\n",
            "day           -0.0014      0.000     -2.749      0.006      -0.002      -0.000\n",
            "==============================================================================\n",
            "Omnibus:                     3161.875   Durbin-Watson:                   0.446\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              520.294\n",
            "Skew:                           0.102   Prob(JB):                    1.05e-113\n",
            "Kurtosis:                       1.962   Cond. No.                     1.55e+04\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 1.55e+04. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}