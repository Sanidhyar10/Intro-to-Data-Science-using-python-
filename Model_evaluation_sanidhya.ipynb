{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sanidhyar10/Intro-to-Data-Science-using-python-/blob/main/Model_evaluation_sanidhya.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5: Model Evaluation"
      ],
      "metadata": {
        "id": "tSPRgotvFeG2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qemCApsAFNpZ"
      },
      "outputs": [],
      "source": [
        "# To perform model evaluation using Python, especially with a classification model,\n",
        "# you can use various metrics such as accuracy, precision, recall, F1 score, and confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  How to Perform Model Evaluation Using R/Python"
      ],
      "metadata": {
        "id": "d3gYZfKUFmSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Load the dataset (replace 'bank.csv' with the actual path to your dataset)\n",
        "bank_data = pd.read_csv('/content/bank.csv')\n",
        "\n",
        "# Replace these columns with your actual predictor and response variable names\n",
        "predictor_columns = [\"age\", \"balance\", \"day\", \"duration\", \"campaign\", \"pdays\", \"previous\"]\n",
        "response_column = \"deposit\"\n",
        "\n",
        "# Assuming categorical variables are already one-hot encoded\n",
        "# If not, use bank_data = pd.get_dummies(bank_data, columns=[\"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\", \"contact\", \"month\", \"poutcome\"])\n",
        "\n",
        "# Convert 'yes' and 'no' to 1 and 0\n",
        "bank_data[response_column] = bank_data[response_column].map({'yes': 1, 'no': 0})\n",
        "\n",
        "# Split the data into training and test sets\n",
        "bank_train, bank_test = train_test_split(bank_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the decision tree model\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(bank_train[predictor_columns], bank_train[response_column])\n",
        "\n",
        "# Make predictions on the test set\n",
        "ypred = model.predict(bank_test[predictor_columns])\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(bank_test[response_column], ypred)\n",
        "precision = precision_score(bank_test[response_column], ypred, pos_label=1)  # Specify pos_label\n",
        "recall = recall_score(bank_test[response_column], ypred)\n",
        "f1 = f1_score(bank_test[response_column], ypred)\n",
        "conf_matrix = confusion_matrix(bank_test[response_column], ypred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "rSYwQqEOFmj_",
        "outputId": "4e305057-561a-4535-a2cc-155f990d3e9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.703090013434841\n",
            "Precision: 0.6894934333958724\n",
            "Recall: 0.6888472352389878\n",
            "F1 Score: 0.6891701828410689\n",
            "Confusion Matrix:\n",
            "[[835 331]\n",
            " [332 735]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Accounting for Unequal Error Costs Using R/Python"
      ],
      "metadata": {
        "id": "4jr8bH3aGE5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In Python, you can use the class_weight parameter in the DecisionTreeClassifier to account for unequal error costs.\n",
        "# The class_weight parameter allows you to specify weights for each class,\n",
        "# which is useful when dealing with imbalanced datasets or when you want to assign different costs to different types of errors.\n",
        "\n",
        "# Here's how you can achieve this in Python using the Bank dataset:\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load the dataset (replace 'bank.csv' with the actual path to your dataset)\n",
        "bank_data = pd.read_csv('/content/bank.csv')\n",
        "\n",
        "# Replace these columns with your actual predictor and response variable names\n",
        "predictor_columns = [\"age\", \"balance\", \"day\", \"duration\", \"campaign\", \"pdays\", \"previous\"]\n",
        "response_column = \"deposit\"\n",
        "\n",
        "# Assuming categorical variables are already one-hot encoded\n",
        "# If not, use bank_data = pd.get_dummies(bank_data, columns=[\"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\", \"contact\", \"month\", \"poutcome\"])\n",
        "\n",
        "# Convert 'yes' and 'no' to 1 and 0\n",
        "bank_data[response_column] = bank_data[response_column].map({'yes': 1, 'no': 0})\n",
        "\n",
        "# Split the data into training and test sets\n",
        "bank_train, bank_test = train_test_split(bank_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the class weights based on your cost matrix\n",
        "class_weights = {0: 0, 1: 4}  # Replace with your actual cost matrix\n",
        "\n",
        "# Create and train the decision tree model with class weights\n",
        "model_cost = DecisionTreeClassifier(class_weight=class_weights)\n",
        "model_cost.fit(bank_train[predictor_columns], bank_train[response_column])\n",
        "\n",
        "# Make predictions on the test set\n",
        "ypred_cost = model_cost.predict(bank_test[predictor_columns])\n",
        "\n",
        "# Evaluate the model with confusion matrix\n",
        "conf_matrix_cost = confusion_matrix(bank_test[response_column], ypred_cost)\n",
        "\n",
        "print(\"Confusion Matrix with Class Weights:\")\n",
        "print(conf_matrix_cost)\n",
        "\n",
        "\n",
        "# In this example, the class_weight parameter is used to assign different weights to the classes.\n",
        "# The weights are specified in the class_weights dictionary, where the keys are the class labels (0 and 1),\n",
        "# and the values are the corresponding weights.\n",
        "# Replace the class_weights dictionary with the actual weights you want to assign based on your cost matrix.\n"
      ],
      "metadata": {
        "id": "nd8hc-OsGFOu",
        "outputId": "177df34c-ebf2-4dba-8233-e728ad24a367",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix with Class Weights:\n",
            "[[   0 1166]\n",
            " [   0 1067]]\n"
          ]
        }
      ]
    }
  ]
}